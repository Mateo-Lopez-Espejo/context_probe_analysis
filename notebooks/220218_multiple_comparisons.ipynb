{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nems.configs.defaults INFO] Saving log messages to /tmp/nems/NEMS 2022-03-04 180832.log\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from configparser import ConfigParser\n",
    "import pathlib as pl\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import joblib as jl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from src.root_path import config_path\n",
    "from src.visualization.interactive import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  source mult_comp_corr  cluster_threshold region     site context_pair  \\\n0   real          bf_cp                1.0     A1  ley072b        00_01   \n1   real          bf_cp                1.0     A1  ley072b        00_02   \n2   real          bf_cp                1.0     A1  ley072b        00_03   \n3   real          bf_cp                1.0     A1  ley072b        00_04   \n4   real          bf_cp                1.0     A1  ley072b        01_02   \n\n   probe    metric  value            id    trans_pair  stim_count diff_metric  \n0      1  duration    0.0  ley072b-03-1  silence_same           4      dprime  \n1      1  duration    0.0  ley072b-03-1  silence_diff           4      dprime  \n2      1  duration    0.0  ley072b-03-1  silence_diff           4      dprime  \n3      1  duration    0.0  ley072b-03-1  silence_diff           4      dprime  \n4      1  duration    0.0  ley072b-03-1     same_diff           4      dprime  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>mult_comp_corr</th>\n      <th>cluster_threshold</th>\n      <th>region</th>\n      <th>site</th>\n      <th>context_pair</th>\n      <th>probe</th>\n      <th>metric</th>\n      <th>value</th>\n      <th>id</th>\n      <th>trans_pair</th>\n      <th>stim_count</th>\n      <th>diff_metric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>real</td>\n      <td>bf_cp</td>\n      <td>1.0</td>\n      <td>A1</td>\n      <td>ley072b</td>\n      <td>00_01</td>\n      <td>1</td>\n      <td>duration</td>\n      <td>0.0</td>\n      <td>ley072b-03-1</td>\n      <td>silence_same</td>\n      <td>4</td>\n      <td>dprime</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>real</td>\n      <td>bf_cp</td>\n      <td>1.0</td>\n      <td>A1</td>\n      <td>ley072b</td>\n      <td>00_02</td>\n      <td>1</td>\n      <td>duration</td>\n      <td>0.0</td>\n      <td>ley072b-03-1</td>\n      <td>silence_diff</td>\n      <td>4</td>\n      <td>dprime</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>real</td>\n      <td>bf_cp</td>\n      <td>1.0</td>\n      <td>A1</td>\n      <td>ley072b</td>\n      <td>00_03</td>\n      <td>1</td>\n      <td>duration</td>\n      <td>0.0</td>\n      <td>ley072b-03-1</td>\n      <td>silence_diff</td>\n      <td>4</td>\n      <td>dprime</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>real</td>\n      <td>bf_cp</td>\n      <td>1.0</td>\n      <td>A1</td>\n      <td>ley072b</td>\n      <td>00_04</td>\n      <td>1</td>\n      <td>duration</td>\n      <td>0.0</td>\n      <td>ley072b-03-1</td>\n      <td>silence_diff</td>\n      <td>4</td>\n      <td>dprime</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>real</td>\n      <td>bf_cp</td>\n      <td>1.0</td>\n      <td>A1</td>\n      <td>ley072b</td>\n      <td>01_02</td>\n      <td>1</td>\n      <td>duration</td>\n      <td>0.0</td>\n      <td>ley072b-03-1</td>\n      <td>same_diff</td>\n      <td>4</td>\n      <td>dprime</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = ConfigParser()\n",
    "config.read_file(open(config_path / 'settings.ini'))\n",
    "meta = {'reliability': 0.1,  # r value\n",
    "        'smoothing_window': 0,  # ms\n",
    "        'raster_fs': 30,\n",
    "        'montecarlo': 1000,\n",
    "        'zscore': True,\n",
    "        'stim_type': 'permutations'}\n",
    "\n",
    "file_dict = dict(\n",
    "dprime = pl.Path(config['paths']['analysis_cache']) / f'220224_ctx_mod_metric_DF_cluster_mass',\n",
    "mean_difference = pl.Path(config['paths']['analysis_cache']) / f'220301_ctx_mod_metric_DF_mean_diff_cluster_mass',\n",
    "t_statistic = pl.Path(config['paths']['analysis_cache']) / f'220303_ctx_mod_metric_DF_tstat_cluster_mass'\n",
    ")\n",
    "### same example cell as in figure 1 ###\n",
    "prb_idx = 3 - 1# selected probe. the -1 is to acount for 0 not being used\n",
    "ctx_pair = [0,1] # pair of contexts to compare and exemplify d'\n",
    "cellid = 'ARM021b-36-8'\n",
    "\n",
    "\n",
    "def format_dataframe(DF):\n",
    "    ff_analylis = DF.analysis.isin(['SC'])\n",
    "    ff_badsites = ~DF.siteid.isin(['TNC010a'])\n",
    "    mask = ff_analylis & ff_badsites\n",
    "\n",
    "    if 'cluster_threshold' not in DF.columns:\n",
    "        DF['cluster_threshold'] = 0\n",
    "\n",
    "    good_cols =['source', 'mult_comp_corr', 'cluster_threshold', 'region', 'siteid',  'cellid', 'context_pair',\n",
    "                'probe', 'metric', 'value']\n",
    "    filtered = DF.loc[mask, good_cols]\n",
    "\n",
    "    filtered['probe'] = [int(p) for p in filtered['probe']]\n",
    "    filtered['context_pair'] = [f\"{int(cp.split('_')[0]):02d}_{int(cp.split('_')[1]):02d}\"\n",
    "                                for cp in filtered['context_pair']]\n",
    "\n",
    "    # rename metrics and analysis for ease of ploting\n",
    "    filtered['metric'] = filtered['metric'].replace({'significant_abs_mass_center': 'duration',\n",
    "                                                     'significant_abs_sum': \"amplitude\"})\n",
    "\n",
    "    filtered['id'] = filtered['cellid'].fillna(value=filtered['siteid'])\n",
    "    filtered = filtered.drop(columns=['cellid'])\n",
    "    filtered.rename(columns={'siteid':'site'}, inplace=True)\n",
    "\n",
    "    filtered['value'] = filtered['value'].fillna(value=0)\n",
    "\n",
    "    # permutation related preprocesing.\n",
    "    # creates a new column relating probe with  context pairs\n",
    "    ctx = np.asarray([row.split('_') for row in filtered.context_pair], dtype=int)\n",
    "    prb = np.asarray(filtered.probe, dtype=int)\n",
    "\n",
    "    silence = ctx == 0\n",
    "    same = ctx == prb[:,None]\n",
    "    different = np.logical_and(~silence, ~same)\n",
    "\n",
    "    name_arr = np.full_like(ctx, np.nan, dtype=object)\n",
    "    name_arr[silence] = 'silence'\n",
    "    name_arr[same] = 'same'\n",
    "    name_arr[different] = 'diff'\n",
    "    comp_name_arr = np.apply_along_axis('_'.join, 1, name_arr)\n",
    "\n",
    "    # swaps clasification names to not have repetitions i.e. diff_same == same_diff\n",
    "    comp_name_arr[np.where(comp_name_arr == 'same_silence')] = 'silence_same'\n",
    "    comp_name_arr[np.where(comp_name_arr == 'diff_silence')] = 'silence_diff'\n",
    "    comp_name_arr[np.where(comp_name_arr == 'diff_same')] = 'same_diff'\n",
    "    comp_name_arr[np.where(comp_name_arr == 'same_silence')] = 'silence_same'\n",
    "\n",
    "    filtered['trans_pair'] = comp_name_arr\n",
    "\n",
    "\n",
    "    # column specifying number of different sounds used\n",
    "    nstim = filtered.groupby(['id']).agg(stim_count=('probe',lambda x: x.nunique()))\n",
    "    filtered = pd.merge(filtered, nstim, on='id')\n",
    "\n",
    "    return filtered\n",
    "\n",
    "longDF = list()\n",
    "for diff_metric, file in file_dict.items():\n",
    "    df = format_dataframe(jl.load(file))\n",
    "    df['diff_metric'] = diff_metric\n",
    "    longDF.append(df)\n",
    "\n",
    "\n",
    "longDF = pd.concat(longDF, axis=0, ignore_index=True)\n",
    "\n",
    "# longDF = format_dataframe(jl.load(mass_file_diff))\n",
    "\n",
    "longDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['source', 'mult_comp_corr', 'cluster_threshold', 'region', 'site',\n       'context_pair', 'probe', 'metric', 'value', 'id', 'trans_pair',\n       'stim_count', 'diff_metric'],\n      dtype='object')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longDF.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences between mutiple comparisons\n",
    "in the table we see the percentage of context-pair * probe * neuron that are significantly modulate\n",
    "considering different multiple bonferrony corrections for context and probe (bf_cp), context probe time (bf_cpt),\n",
    "neuron context probe time (bf_ncpt), just time (bf_t), old 3 consecutive time bins, and with different\n",
    "cluster thresholds for the cluster mass analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pivoted = longDF.pivot_table(index=['source', 'diff_metric', 'mult_comp_corr', 'cluster_threshold',\n",
    "                                    'region', 'stim_count',\n",
    "                                    'context_pair', 'probe',\n",
    "                                    'id', 'site'],\n",
    "                             columns=['metric'], values='value', aggfunc='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "counts = pivoted.groupby(['source', 'diff_metric', 'mult_comp_corr', 'cluster_threshold']\n",
    "                         ).agg(signif_percent=('duration', lambda x: (x>0).sum()/x.size * 100 ))\n",
    "print(counts)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## different distributions in context modulation space\n",
    "scatter of amplitud and duration of contextual modulations calculated for different time series metrics\n",
    "(dprime, mean difference and  t-statistic) and with different bonferroni corrections\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "mult_comps = ['none', 'bf_cp', 'bf_ncp']\n",
    "clust_threshs = [0.05, 2]\n",
    "toplot = pivoted.loc[idx['real', :, mult_comps, clust_threshs],:].reset_index()\n",
    "\n",
    "scat = px.scatter(data_frame=toplot, x='duration', y='amplitude',\n",
    "                  facet_col='mult_comp_corr', facet_row='diff_metric',\n",
    "                  hover_data=['id', 'context_pair', 'probe'], color='site')\n",
    "\n",
    "_ = scat.update_layout(showlegend=False)\n",
    "_ = scat.update_yaxes(matches=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### big figure output\n",
    "this figure pushes the notebook size over 100MB, which github does not like.\n",
    "Instead of displaying the dynamic figure I can show a much smaller jpeg for long term storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# scat.show() # interactive, big file\n",
    "# png to not fill so much space\n",
    "img_bytes = scat.to_image(format=\"png\")\n",
    "Image(img_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example neuron from the previous plot.\n",
    "this neuron appears on the lowe threshold (permisive) but not high threshold cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# cellid, contexts, probes = 'ARM021b-36-8', (0, 1), 3  # paper example\n",
    "cellid, contexts, probes = 'ARM017a-31-1', (0,3), 3 # odd tail in bf_cp-2.0\n",
    "cellid, contexts, probes = 'TNC008a-05-1', (0,8), 7 # odd tail in bf_cp-2.0\n",
    "\n",
    "dprm = plot_time_ser_quant(cellid, contexts, probes, source='real',\n",
    "                           multiple_comparisons_axis=[1,2], consecutive=0, cluster_threshold=0.05,\n",
    "                           fn_name='t_statistic', meta=meta)\n",
    "psth = plot_psth_pair(cellid, contexts, probes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "subplots = make_subplots(1,2)\n",
    "subplots.update_layout(showlegend=False)\n",
    "_ = subplots.add_traces(psth['data'], rows=[1]*len(psth['data']),cols=[1]*len(psth['data']))\n",
    "_ = subplots.add_vline(x=0, line_width=2, line_color='black', line_dash='dot', opacity=1, row=1, col=1)\n",
    "_ = subplots.add_traces(dprm['data'], rows=[1]*len(dprm['data']),cols=[2]*len(dprm['data']))\n",
    "\n",
    "# subplots.show()\n",
    "subplots_bytes = subplots.to_image(format=\"png\")\n",
    "Image(subplots_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find example clearly divergent between thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "clust_threshs = [1.0, 2.0]\n",
    "filt = pivoted.loc[idx['real', 'dprime', 'bf_cp', clust_threshs],:].reset_index()\n",
    "piv2 = filt.pivot_table(index=['context_pair', 'probe', 'id'], columns=['cluster_threshold'], values='amplitude',\n",
    "                        aggfunc='first')\n",
    "piv2['diff'] = piv2[1.0] - piv2[2.0]\n",
    "piv2.sort_values(['diff'], ascending=[False], inplace=True)\n",
    "piv2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cellid, contexts, probes = 'TNC006a-07-1', (2,10), 2 # huge difference between thresholds\n",
    "\n",
    "meta = {'reliability': 0.1,  # r value\n",
    "        'smoothing_window': 0,  # ms\n",
    "        'raster_fs': 30,\n",
    "        'montecarlo': 1000,\n",
    "        'zscore': True,\n",
    "        'stim_type': 'permutations'}\n",
    "\n",
    "\n",
    "psth = plot_psth_pair(cellid, contexts, probes)\n",
    "\n",
    "dprm_th_lo = plot_time_ser_quant(cellid, contexts, probes, source='real',\n",
    "                             multiple_comparisons_axis=[1,2], consecutive=0, cluster_threshold=1.0, fn_name='dprime',\n",
    "                             meta=meta)\n",
    "\n",
    "dprm_th_hi = plot_time_ser_quant(cellid, contexts, probes, source='real',\n",
    "                             multiple_comparisons_axis=[1,2], consecutive=0, cluster_threshold=2.0, fn_name='dprime',\n",
    "                             meta=meta)\n",
    "subplots = make_subplots(1,3)\n",
    "subplots.update_layout(showlegend=False)\n",
    "_ = subplots.add_traces(psth['data'], rows=[1]*len(psth['data']),cols=[1]*len(psth['data']))\n",
    "_ = subplots.add_vline(x=0, line_width=2, line_color='black', line_dash='dot', opacity=1, row=1, col=1)\n",
    "_ = subplots.add_traces(dprm_th_lo['data'], rows=[1]*len(dprm_th_lo['data']),cols=[2]*len(dprm_th_lo['data']))\n",
    "_ = subplots.add_traces(dprm_th_hi['data'], rows=[1]*len(dprm_th_hi['data']),cols=[3]*len(dprm_th_hi['data']))\n",
    "\n",
    "subplots.show()\n",
    "# subplots_bytes = subplots.to_image(format=\"png\")\n",
    "# Image(subplots_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# check only good examples of the t-statistic-based metric distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "toplot = pivoted.loc[idx['real', 't_statistic', 'bf_cp', 0.05],:].reset_index()\n",
    "\n",
    "scat = px.scatter(data_frame=toplot, x='duration', y='amplitude',\n",
    "                  hover_data=['id', 'context_pair', 'probe'], color='region')\n",
    "\n",
    "# _ = scat.update_layout(showlegend=False)\n",
    "_ = scat.update_yaxes(matches=None)\n",
    "scat.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cellid, contexts, probes = 'TNC006a-07-1', (2,10), 2\n",
    "# cellid, contexts, probes = 'CRD011c-50-4', (0,4), 4\n",
    "\n",
    "meta = {'reliability': 0.1,  # r value\n",
    "        'smoothing_window': 0,  # ms\n",
    "        'raster_fs': 30,\n",
    "        'montecarlo': 1000,\n",
    "        'zscore': True,\n",
    "        'stim_type': 'permutations'}\n",
    "\n",
    "\n",
    "psth = plot_psth_pair(cellid, contexts, probes)\n",
    "\n",
    "dprm_th_hi = plot_time_ser_quant(cellid, contexts, probes, source='real',\n",
    "                             multiple_comparisons_axis=None, consecutive=0, cluster_threshold=0.05, fn_name='t_statistic',\n",
    "                             meta=meta)\n",
    "subplots = make_subplots(1,2)\n",
    "subplots.update_layout(showlegend=False)\n",
    "_ = subplots.add_traces(psth['data'], rows=[1]*len(psth['data']),cols=[1]*len(psth['data']))\n",
    "_ = subplots.add_vline(x=0, line_width=2, line_color='black', line_dash='dot', opacity=1, row=1, col=1)\n",
    "_ = subplots.add_traces(dprm_th_hi['data'], rows=[1]*len(dprm_th_hi['data']),cols=[2]*len(dprm_th_hi['data']))\n",
    "\n",
    "subplots.show()\n",
    "# subplots_bytes = subplots.to_image(format=\"png\")\n",
    "# Image(subplots_bytes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}