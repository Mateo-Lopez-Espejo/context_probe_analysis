{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nems.configs.defaults INFO] Saving log messages to /tmp/nems/NEMS 2021-09-13 092422.log\n",
      "/auto/users/mateo/nems_db/nems_lbhb/SettingXML.py:66: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  {K: SubEl.get(K) for K in SubEl.keys() if K is not 'name'}\n",
      "/auto/users/mateo/nems_db/nems_lbhb/SettingXML.py:76: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  {K: SubEl.get(K) for K in SubEl.keys() if K is not 'name'}\n",
      "/auto/users/mateo/nems_db/nems_lbhb/SettingXML.py:81: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  {K: SubEl.get(K) for K in SubEl.keys() if K is not 'name'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing region_map: site ley058d has undefined region\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[numexpr.utils INFO] NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import itertools as itt\n",
    "\n",
    "import joblib as jl\n",
    "import pathlib as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from src.root_path import config_path\n",
    "from configparser import ConfigParser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "config.read_file(open(config_path / 'settings.ini'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#general plottin formating\n",
    "plt.style.use(['dark_background', config_path / 'notebook.mplstyle'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 4 sound file\n",
    "DF4_file = pl.Path(config['paths']['analysis_cache']) /'210302_consolidated_summary_DF_alpha_0.05/dprime_absolute-None_montecarlo-1000_raster_fs-30_reliability-0.1_smoothing_window-0_zscore-True'\n",
    "DF4 = jl.load(DF4_file)\n",
    "\n",
    "# 10 soundfile\n",
    "DF10_file = pl.Path(config['paths']['analysis_cache']) /'210902_consolidated_summary_DF_alpha_0.05/dprime_absolute-None_montecarlo-1000_raster_fs-30_reliability-0.1_smoothing_window-0_stim_type-permutations_zscore-True'\n",
    "\n",
    "DF10 = jl.load(DF10_file)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no mean_signif_type, taking all values\n",
      "no stim_type, taking all values\n"
     ]
    },
    {
     "data": {
      "text/plain": "           analysis mult_comp_corr region context_pair  probe  \\\n75735   single cell  consecutive_4    PEG        00_01      1   \n75736   single cell  consecutive_4    PEG        00_01      1   \n75737   single cell  consecutive_4    PEG        00_01      1   \n75738   single cell  consecutive_4    PEG        00_01      1   \n75739   single cell  consecutive_4    PEG        00_01      1   \n...             ...            ...    ...          ...    ...   \n854695   population  consecutive_4     A1        07_09     10   \n854696   population  consecutive_4     A1        07_10     10   \n854697   population  consecutive_4     A1        08_09     10   \n854698   population  consecutive_4     A1        08_10     10   \n854699   population  consecutive_4     A1        09_10     10   \n\n                     metric  value            id    trans_pair  nsounds  \n75735   center of mass (ms)    0.0  AMT028b-01-1  silence_same        4  \n75736   center of mass (ms)    0.0  AMT028b-01-2  silence_same        4  \n75737   center of mass (ms)    0.0  AMT028b-04-1  silence_same        4  \n75738   center of mass (ms)    0.0  AMT028b-06-1  silence_same        4  \n75739   center of mass (ms)    0.0  AMT028b-07-1  silence_same        4  \n...                     ...    ...           ...           ...      ...  \n854695     integral (d'*ms)    0.0       TNC015a     diff_diff       10  \n854696     integral (d'*ms)    0.0       TNC015a     same_diff       10  \n854697     integral (d'*ms)    0.0       TNC015a     diff_diff       10  \n854698     integral (d'*ms)    0.0       TNC015a     same_diff       10  \n854699     integral (d'*ms)    0.0       TNC015a     same_diff       10  \n\n[350060 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>analysis</th>\n      <th>mult_comp_corr</th>\n      <th>region</th>\n      <th>context_pair</th>\n      <th>probe</th>\n      <th>metric</th>\n      <th>value</th>\n      <th>id</th>\n      <th>trans_pair</th>\n      <th>nsounds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>75735</th>\n      <td>single cell</td>\n      <td>consecutive_4</td>\n      <td>PEG</td>\n      <td>00_01</td>\n      <td>1</td>\n      <td>center of mass (ms)</td>\n      <td>0.0</td>\n      <td>AMT028b-01-1</td>\n      <td>silence_same</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75736</th>\n      <td>single cell</td>\n      <td>consecutive_4</td>\n      <td>PEG</td>\n      <td>00_01</td>\n      <td>1</td>\n      <td>center of mass (ms)</td>\n      <td>0.0</td>\n      <td>AMT028b-01-2</td>\n      <td>silence_same</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75737</th>\n      <td>single cell</td>\n      <td>consecutive_4</td>\n      <td>PEG</td>\n      <td>00_01</td>\n      <td>1</td>\n      <td>center of mass (ms)</td>\n      <td>0.0</td>\n      <td>AMT028b-04-1</td>\n      <td>silence_same</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75738</th>\n      <td>single cell</td>\n      <td>consecutive_4</td>\n      <td>PEG</td>\n      <td>00_01</td>\n      <td>1</td>\n      <td>center of mass (ms)</td>\n      <td>0.0</td>\n      <td>AMT028b-06-1</td>\n      <td>silence_same</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>75739</th>\n      <td>single cell</td>\n      <td>consecutive_4</td>\n      <td>PEG</td>\n      <td>00_01</td>\n      <td>1</td>\n      <td>center of mass (ms)</td>\n      <td>0.0</td>\n      <td>AMT028b-07-1</td>\n      <td>silence_same</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>854695</th>\n      <td>population</td>\n      <td>consecutive_4</td>\n      <td>A1</td>\n      <td>07_09</td>\n      <td>10</td>\n      <td>integral (d'*ms)</td>\n      <td>0.0</td>\n      <td>TNC015a</td>\n      <td>diff_diff</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>854696</th>\n      <td>population</td>\n      <td>consecutive_4</td>\n      <td>A1</td>\n      <td>07_10</td>\n      <td>10</td>\n      <td>integral (d'*ms)</td>\n      <td>0.0</td>\n      <td>TNC015a</td>\n      <td>same_diff</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>854697</th>\n      <td>population</td>\n      <td>consecutive_4</td>\n      <td>A1</td>\n      <td>08_09</td>\n      <td>10</td>\n      <td>integral (d'*ms)</td>\n      <td>0.0</td>\n      <td>TNC015a</td>\n      <td>diff_diff</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>854698</th>\n      <td>population</td>\n      <td>consecutive_4</td>\n      <td>A1</td>\n      <td>08_10</td>\n      <td>10</td>\n      <td>integral (d'*ms)</td>\n      <td>0.0</td>\n      <td>TNC015a</td>\n      <td>same_diff</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>854699</th>\n      <td>population</td>\n      <td>consecutive_4</td>\n      <td>A1</td>\n      <td>09_10</td>\n      <td>10</td>\n      <td>integral (d'*ms)</td>\n      <td>0.0</td>\n      <td>TNC015a</td>\n      <td>same_diff</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n<p>350060 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mult_comp_cont = 4\n",
    "# pulls DF, removes unused columns and data, refactor redundant id columns and create probe_id\n",
    "def format_dataframe(DF):\n",
    "    ff_probe = DF.probe != 'mean'\n",
    "    ff_pairs = DF.context_pair != 'mean'\n",
    "    try:\n",
    "        ff_mean = DF.mean_signif_type == 'shuffles'\n",
    "    except:\n",
    "        print('no mean_signif_type, taking all values')\n",
    "        ff_mean = pd.Series(np.full(DF.shape[0], True))\n",
    "\n",
    "\n",
    "    try:\n",
    "        ff_stim = DF.stim_type == 'permutations'\n",
    "    except:\n",
    "        print('no stim_type, taking all values')\n",
    "        ff_stim = pd.Series(np.full(DF.shape[0], True))\n",
    "\n",
    "\n",
    "    ff_analylis = DF.analysis.isin(['SC', 'fdPCA'])\n",
    "    # ff_corr = DF.mult_comp_corr == 'consecutive_3'\n",
    "    ff_corr = DF.mult_comp_corr == f'consecutive_{mult_comp_cont}'\n",
    "    ff_metric = DF.metric.isin(['significant_abs_mass_center', 'significant_abs_sum'])\n",
    "\n",
    "    good_cols =['analysis', 'mult_comp_corr', 'region', 'siteid',  'cellid', 'context_pair',\n",
    "                'probe', 'metric', 'value']\n",
    "    filtered = DF.loc[ff_stim & ff_mean & ff_pairs & ff_probe & ff_analylis & ff_corr & ff_metric, good_cols]\n",
    "\n",
    "    filtered['probe'] = [int(p) for p in filtered['probe']]\n",
    "    filtered['context_pair'] = [f\"{int(cp.split('_')[0]):02d}_{int(cp.split('_')[1]):02d}\"\n",
    "                                for cp in filtered['context_pair']]\n",
    "\n",
    "    # rename metrics and analysis for ease of ploting\n",
    "    filtered['metric'] = filtered['metric'].replace({'significant_abs_mass_center': 'center of mass (ms)',\n",
    "                                                     'significant_abs_mean': \"mean d'\",\n",
    "                                                     'significant_abs_sum': \"integral (d'*ms)\"})\n",
    "    filtered['analysis'] = filtered['analysis'].replace({'SC': 'single cell',\n",
    "                                                         'fdPCA': 'population',\n",
    "                                                         'pdPCA': 'probewise pop',\n",
    "                                                         'LDA': 'pop ceiling'})\n",
    "\n",
    "    filtered['id'] = filtered['cellid'].fillna(value=filtered['siteid'])\n",
    "    filtered = filtered.drop(columns=['cellid', 'siteid'])\n",
    "\n",
    "    filtered['value'] = filtered['value'].fillna(value=0)\n",
    "\n",
    "    # permutation related preprocesing.\n",
    "    # creates a new column relating probe with  context pairs\n",
    "    ctx = np.asarray([row.split('_') for row in filtered.context_pair], dtype=int)\n",
    "    prb = np.asarray(filtered.probe, dtype=int)\n",
    "\n",
    "    silence = ctx == 0\n",
    "    same = ctx == prb[:,None]\n",
    "    different = np.logical_and(~silence, ~same)\n",
    "\n",
    "    name_arr = np.full_like(ctx, np.nan, dtype=object)\n",
    "    name_arr[silence] = 'silence'\n",
    "    name_arr[same] = 'same'\n",
    "    name_arr[different] = 'diff'\n",
    "    comp_name_arr = np.apply_along_axis('_'.join, 1, name_arr)\n",
    "\n",
    "    # swaps clasification names to not have repetitions i.e. diff_same == same_diff\n",
    "    comp_name_arr[np.where(comp_name_arr == 'same_silence')] = 'silence_same'\n",
    "    comp_name_arr[np.where(comp_name_arr == 'diff_silence')] = 'silence_diff'\n",
    "    comp_name_arr[np.where(comp_name_arr == 'diff_same')] = 'same_diff'\n",
    "    comp_name_arr[np.where(comp_name_arr == 'same_silence')] = 'silence_same'\n",
    "\n",
    "    filtered['trans_pair'] = comp_name_arr\n",
    "\n",
    "    ord_cols = ['analysis', 'region', 'id', 'context_pair', 'trans_pair', 'probe', 'metric', 'value']\n",
    "    pivot_idx = [col for col in ord_cols if col not in ['value', 'metric']]\n",
    "    pivoted = filtered.pivot_table(index=pivot_idx, columns='metric', values='value', aggfunc='first').reset_index()\n",
    "\n",
    "    full_long = filtered # saves long format for subsamplig analysis\n",
    "\n",
    "    return pivoted, full_long\n",
    "\n",
    "pivoted, full_long = pd.DataFrame(), pd.DataFrame()\n",
    "for df, nsounds in zip([DF4, DF10], [4, 10]):\n",
    "    pvtd, fl_lg = format_dataframe(df)\n",
    "    pvtd['nsounds'] = nsounds\n",
    "    fl_lg['nsounds'] = nsounds\n",
    "    pivoted = pivoted.append(pvtd)\n",
    "    full_long = full_long.append(fl_lg)\n",
    "\n",
    "del(fl_lg, pvtd)\n",
    "display(full_long)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 mean duration  mean amplitude  total  \\\nanalysis    region trans_pair                                           \npopulation  A1     diff_diff        262.126327      295.537675   2352   \n                   same_diff        236.317175      307.331638    732   \n                   silence_diff     216.244759      379.872559    732   \n                   silence_same     208.043779      465.515417    124   \n            PEG    diff_diff        115.342923      297.866624    228   \n                   same_diff        131.897413      328.627656    228   \n                   silence_diff     136.095736      393.258078    228   \n                   silence_same     167.972786      429.614277     76   \nsingle cell A1     diff_diff        318.940545      181.916530  93864   \n                   same_diff        308.953268      186.413325  27174   \n                   silence_diff     289.390279      209.432437  27174   \n                   silence_same     285.887404      225.288201   4118   \n            PEG    diff_diff        173.334498      225.751467   5400   \n                   same_diff        203.595567      225.590667   5400   \n                   silence_diff     197.581493      242.205015   5400   \n                   silence_same     252.343107      231.156172   1800   \n\n                                 n_signif  significant %  \nanalysis    region trans_pair                             \npopulation  A1     diff_diff        645.0      27.423469  \n                   same_diff        189.0      25.819672  \n                   silence_diff     304.0      41.530055  \n                   silence_same      52.0      41.935484  \n            PEG    diff_diff         60.0      26.315789  \n                   same_diff         62.0      27.192982  \n                   silence_diff      91.0      39.912281  \n                   silence_same      27.0      35.526316  \nsingle cell A1     diff_diff       4235.0       4.511847  \n                   same_diff       1125.0       4.139987  \n                   silence_diff    1647.0       6.060941  \n                   silence_same     245.0       5.949490  \n            PEG    diff_diff        232.0       4.296296  \n                   same_diff        244.0       4.518519  \n                   silence_diff     287.0       5.314815  \n                   silence_same     124.0       6.888889  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>mean duration</th>\n      <th>mean amplitude</th>\n      <th>total</th>\n      <th>n_signif</th>\n      <th>significant %</th>\n    </tr>\n    <tr>\n      <th>analysis</th>\n      <th>region</th>\n      <th>trans_pair</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">population</th>\n      <th rowspan=\"4\" valign=\"top\">A1</th>\n      <th>diff_diff</th>\n      <td>262.126327</td>\n      <td>295.537675</td>\n      <td>2352</td>\n      <td>645.0</td>\n      <td>27.423469</td>\n    </tr>\n    <tr>\n      <th>same_diff</th>\n      <td>236.317175</td>\n      <td>307.331638</td>\n      <td>732</td>\n      <td>189.0</td>\n      <td>25.819672</td>\n    </tr>\n    <tr>\n      <th>silence_diff</th>\n      <td>216.244759</td>\n      <td>379.872559</td>\n      <td>732</td>\n      <td>304.0</td>\n      <td>41.530055</td>\n    </tr>\n    <tr>\n      <th>silence_same</th>\n      <td>208.043779</td>\n      <td>465.515417</td>\n      <td>124</td>\n      <td>52.0</td>\n      <td>41.935484</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">PEG</th>\n      <th>diff_diff</th>\n      <td>115.342923</td>\n      <td>297.866624</td>\n      <td>228</td>\n      <td>60.0</td>\n      <td>26.315789</td>\n    </tr>\n    <tr>\n      <th>same_diff</th>\n      <td>131.897413</td>\n      <td>328.627656</td>\n      <td>228</td>\n      <td>62.0</td>\n      <td>27.192982</td>\n    </tr>\n    <tr>\n      <th>silence_diff</th>\n      <td>136.095736</td>\n      <td>393.258078</td>\n      <td>228</td>\n      <td>91.0</td>\n      <td>39.912281</td>\n    </tr>\n    <tr>\n      <th>silence_same</th>\n      <td>167.972786</td>\n      <td>429.614277</td>\n      <td>76</td>\n      <td>27.0</td>\n      <td>35.526316</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">single cell</th>\n      <th rowspan=\"4\" valign=\"top\">A1</th>\n      <th>diff_diff</th>\n      <td>318.940545</td>\n      <td>181.916530</td>\n      <td>93864</td>\n      <td>4235.0</td>\n      <td>4.511847</td>\n    </tr>\n    <tr>\n      <th>same_diff</th>\n      <td>308.953268</td>\n      <td>186.413325</td>\n      <td>27174</td>\n      <td>1125.0</td>\n      <td>4.139987</td>\n    </tr>\n    <tr>\n      <th>silence_diff</th>\n      <td>289.390279</td>\n      <td>209.432437</td>\n      <td>27174</td>\n      <td>1647.0</td>\n      <td>6.060941</td>\n    </tr>\n    <tr>\n      <th>silence_same</th>\n      <td>285.887404</td>\n      <td>225.288201</td>\n      <td>4118</td>\n      <td>245.0</td>\n      <td>5.949490</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">PEG</th>\n      <th>diff_diff</th>\n      <td>173.334498</td>\n      <td>225.751467</td>\n      <td>5400</td>\n      <td>232.0</td>\n      <td>4.296296</td>\n    </tr>\n    <tr>\n      <th>same_diff</th>\n      <td>203.595567</td>\n      <td>225.590667</td>\n      <td>5400</td>\n      <td>244.0</td>\n      <td>4.518519</td>\n    </tr>\n    <tr>\n      <th>silence_diff</th>\n      <td>197.581493</td>\n      <td>242.205015</td>\n      <td>5400</td>\n      <td>287.0</td>\n      <td>5.314815</td>\n    </tr>\n    <tr>\n      <th>silence_same</th>\n      <td>252.343107</td>\n      <td>231.156172</td>\n      <td>1800</td>\n      <td>124.0</td>\n      <td>6.888889</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# counts the total number of values for each comparison (SC, fDPCA) x (sile_diff, sile_same, diff_diff, same_diff)\n",
    "# counts the proportion of signifciant vs non singificant(zero-zero) values\n",
    "# decimates the more numerous comparisons??\n",
    "\n",
    "# set the array to group by id, context_pair, and probe. Keeping analysis, region and transision_pair\n",
    "# the final array should have analysis, region and trans pair as rowns, and total count, and significants as columns\n",
    "\n",
    "def nozero_mean(arr):\n",
    "    arr[arr==0] = np.nan\n",
    "    return np.nanmean(arr)\n",
    "\n",
    "def nozero_count(arr):\n",
    "    return np.sum(arr>0)\n",
    "\n",
    "def corrected_count(arr):\n",
    "    n_comparisons = np.size(arr)\n",
    "    alpha = 0.05**mult_comp_cont * (30 - mult_comp_cont)\n",
    "    chance = n_comparisons * alpha\n",
    "\n",
    "    raw_count = np.sum(arr>0)\n",
    "    if raw_count > chance:\n",
    "        corr_count = raw_count\n",
    "    else:\n",
    "        corr_count = 0\n",
    "    return corr_count\n",
    "\n",
    "def nozero_proportion(arr):\n",
    "    return np.sum(arr>0) / np.size(arr)\n",
    "\n",
    "def nozero_percentage(arr):\n",
    "    return np.sum(arr>0) / np.size(arr) *100\n",
    "\n",
    "def corrected_proportion(arr):\n",
    "    n_comparisons = np.size(arr)\n",
    "    alpha = 0.05**mult_comp_cont * (30 - mult_comp_cont)\n",
    "    chance = n_comparisons * alpha\n",
    "\n",
    "    raw_count = np.sum(arr>0)\n",
    "    if raw_count > chance:\n",
    "        corr_count = raw_count\n",
    "    else:\n",
    "        corr_count = 0\n",
    "    return corr_count / np.size(arr)\n",
    "\n",
    "filtered = full_long\n",
    "group_ready = pivoted.set_index(['analysis', 'region', 'trans_pair']).loc[:, filtered.metric.unique()]\n",
    "agg_funcs = {'center of mass (ms)': [('mean duration', nozero_mean)],\n",
    "             \"integral (d'*ms)\": [('mean amplitude', nozero_mean),\n",
    "                                     ('total', 'size'),\n",
    "                                     ('n_signif', nozero_count)]}\n",
    "\n",
    "grouped = group_ready.groupby(['analysis', 'region', 'trans_pair']).agg(agg_funcs)\n",
    "grouped.columns = grouped.columns.droplevel(0)\n",
    "grouped['significant %'] = grouped.n_signif / grouped.total * 100\n",
    "\n",
    "display(grouped)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## count number of cells or sites with significant contextual effects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "single cell 4 sounds\n",
      "375 of 862 total modulated neurons/PCs. 43.50%\n",
      "1463 of 34480 total significant instances, 4.24%\n",
      "modulated neurons/PCs have 9.75% significant instances on average\n",
      "sites have 42.27% of modulated neurons on average\n",
      "\n",
      "single cell 10 sounds\n",
      "199 of 247 total modulated neurons/PCs. 80.57%\n",
      "6676 of 135850 total significant instances, 4.91%\n",
      "modulated neurons/PCs have 6.10% significant instances on average\n",
      "sites have 78.95% of modulated neurons on average\n",
      "\n",
      "population 4 sounds\n",
      "35 of 35 total modulated neurons/PCs. 100.00%\n",
      "428 of 1400 total significant instances, 30.57%\n",
      "modulated neurons/PCs have 30.57% significant instances on average\n",
      "\n",
      "population 10 sounds\n",
      "6 of 6 total modulated neurons/PCs. 100.00%\n",
      "1002 of 3300 total significant instances, 30.36%\n",
      "modulated neurons/PCs have 30.36% significant instances on average\n"
     ]
    }
   ],
   "source": [
    "# analyses = ['single cell', 'population', 'probewise pop', 'pop ceiling'] # 4 sounds\n",
    "analyses = ['single cell', 'population']\n",
    "nsounds = [4, 10]# 10 sounds\n",
    "\n",
    "for analysis, ns in itt.product(analyses, nsounds):\n",
    "    print(f'\\n{analysis} {ns} sounds')\n",
    "    all_id_df= pivoted.loc[(pivoted.nsounds == ns) & (pivoted.analysis == analysis), ['id', \"integral (d'*ms)\"]]\n",
    "\n",
    "    # count of cells or sites with significant instances\n",
    "    all_id_count = len(all_id_df.id.unique())\n",
    "    good_id_df= all_id_df.loc[(all_id_df[\"integral (d'*ms)\"] > 0), ['id']]\n",
    "    good_id_count = len(good_id_df.id.unique())\n",
    "    print(f'{good_id_count} of {all_id_count} total modulated neurons/PCs. {good_id_count/all_id_count*100:.2f}%')\n",
    "\n",
    "    # total count of significant instances\n",
    "    total_instances = all_id_df[\"integral (d'*ms)\"].shape[0]\n",
    "    significant_instances = np.sum(all_id_df[\"integral (d'*ms)\"] > 0)\n",
    "    print(f\"{significant_instances} of {total_instances} total significant instances, {significant_instances/total_instances*100:.2f}%\")\n",
    "\n",
    "    # count of significant instances per neuron or PC, corrected for multiple comparisons\n",
    "    signif_prop_per_neuron = all_id_df.groupby('id').agg(corr_signif_prop=(\"integral (d'*ms)\",corrected_proportion))\n",
    "    modulated_neurons =  signif_prop_per_neuron.loc[signif_prop_per_neuron.corr_signif_prop > 0]\n",
    "    print(f\"modulated neurons/PCs have {np.mean(modulated_neurons.values)*100 :.2f}% significant instances on average\")\n",
    "\n",
    "    # count of significant neurons per site\n",
    "    if analysis == 'single cell':\n",
    "        signif_prop_per_neuron = signif_prop_per_neuron.reset_index()\n",
    "        signif_prop_per_neuron['site'] = signif_prop_per_neuron['id'].apply(lambda x: x[:7])\n",
    "        gp = signif_prop_per_neuron.groupby('site').agg(\n",
    "            signif_neu_prop=('corr_signif_prop', lambda x: np.sum(x>0)/np.size(x)))\n",
    "        print(f\"sites have {np.mean(gp.values)*100 :.2f}% of modulated neurons on average\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}